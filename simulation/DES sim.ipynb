{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd; import numpy as np; import os as os; import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt; import seaborn as sns;  import scipy.interpolate as sp\n",
    "import statsmodels.formula.api as smf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.name==\"nt\":\n",
    "    path =\"J:\\\\Project\\\\Cost_Effectiveness\\\\dev\\\\\"\n",
    "else:\n",
    "    path = \"\\home\\\\j\\\\Project\\Cost_Effectiveness\\\\dev\\\\\"\n",
    "    \n",
    "ltable_path =\"data\\\\gbd\"\n",
    "all_data = \"data_processed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_death_df = pd.read_csv(path+'\\\\data_processed\\\\Mortality_Rates.csv')\n",
    "ihd_death_df = pd.read_csv(path +'\\\\data_processed\\\\ihd_mortality_rate.csv')\n",
    "ihd_incidence_df = pd.read_csv(path + '\\\\data_processed\\\\IHD incidence rates.csv')\n",
    "cohort = pd.read_csv(path+all_data+\"\\\\level2_population.csv\")\n",
    "cohort.rename(columns={'age':'Age', 'year_id':'Year', 'IHD':'IHD incidence'}, inplace=True) ## this needs to change\n",
    "ltable = pd.read_csv(path+ltable_path+ \"\\\\interpolated_reference_life_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an interpolator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### interpolator\n",
    "## Per Alec's sugeestion turn this into a class\n",
    "def gen_curve(df, df_id='Mortality_Rate', time =24, inv=0):\n",
    "    df['inv_prob'] =  np.exp(-df[df_id])\n",
    "    df.Year -= np.min(df.Year)\n",
    "    df.Age -= df.Year \n",
    "    df = df[df.Age>0]\n",
    "    df = df[df.Age<=80]\n",
    "    df['cumprod'] = df.groupby(['Age', 'sex']).inv_prob.agg(np.cumprod)\n",
    "    \n",
    "    df.Year+=1\n",
    "    # could not control when random num was out of bounds high or low\n",
    "    ## function defined below takes twice the time now... not worrying about that\n",
    "    for i in np.arange(2):\n",
    "        for s in np.unique(df.sex):\n",
    "                temp = pd.DataFrame(columns=df.columns)\n",
    "                temp['Age'] =np.unique(df.Age)\n",
    "                temp['sex']= s\n",
    "                temp['Year']=np.where(i==1, 0, time)\n",
    "                temp['cumprod'] = i\n",
    "                df = df.append(temp)\n",
    "            \n",
    "    model= sp.LinearNDInterpolator(df[['cumprod','Age', 'sex']], df['Year'])\n",
    "    ## I need to backcalc time didn't know of a better way.\n",
    "    ## I could add another dim to interpolation (current year(i.e. self.clock),\n",
    "    #but python stalled out in calcing that many dims\n",
    "    inv_model = sp.LinearNDInterpolator(df[['Year','Age', 'sex']],df['cumprod'])\n",
    "    \n",
    "    def func(self, ind, rand_seq, name):\n",
    "               \n",
    "        df =self.attributes.iloc[ind]\n",
    "        # convert into rate ## check if there is an easier way or if the math works. do I need to worry about time?\n",
    "        rand_seq = -np.log(1-(1-rand_seq))\n",
    "        rand_seq += self.rate_adj[name][ind,0].reshape(len(ind[0],))## check the ordering\n",
    "        rand_seq*= self.rate_adj[name][ind,1].reshape(len(ind[0],))\n",
    "        rand_seq = np.exp(-rand_seq)\n",
    "        df['cumprod'] =rand_seq.T\n",
    "        fit =model(df[['cumprod','Age', 'sex']])\n",
    "        fit = np.round(fit,3)\n",
    "        return fit\n",
    "    \n",
    "    def invfunc(self,ind, name):\n",
    "        df =self.attributes.iloc[ind]\n",
    "        time = self.clock[ind]\n",
    "        df['Year'] =time\n",
    "        fit =np.array(inv_model(df[['Year','Age', 'sex']]))\n",
    "        # convert into rate ##  check if there is an easier way or if the math works\n",
    "        fit = -np.log(1-(1-fit))\n",
    "        fit /= self.rate_adj[name][ind,1].reshape(len(ind[0]),)\n",
    "        fit -= self.rate_adj[name][ind,0].reshape(len(ind[0]),)\n",
    "        fit = np.exp(-fit)\n",
    "        fit = np.round(fit,3)\n",
    "        return fit\n",
    "    \n",
    "           \n",
    "    return {'func':func, 'invfunc': invfunc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class sim(object):\n",
    "    '''TODO: add documentation, write some test to avoid duplicates\n",
    "    FIX: IHD dead indicator'''\n",
    "    \n",
    "\n",
    "    def __init__(self,n=2e4, time =24):\n",
    "        \n",
    "        self.n = int(n)\n",
    "        self.time = int(time)\n",
    "        self.init_attributes = pd.DataFrame()\n",
    "        \n",
    "        \n",
    "        ## define stuff that will be used later on\n",
    "        self.events= {}\n",
    "        self.event_names =[]\n",
    "        self.updates = {}\n",
    "        self.deadly_events = []\n",
    "        self.init_rate_adj = {}\n",
    "        self.init_at_risk = pd.DataFrame()\n",
    "     \n",
    "    def add_attribute(self,colnames, data):\n",
    "        ## should write in a check to see if att is already defined.\n",
    "        self.init_attributes[colnames]=data\n",
    "    def add_events(self,name, funcs_dict, deadly, at_risk_ind ):\n",
    "        self.event_names.append(name)\n",
    "        self.events.update({name: funcs_dict})\n",
    "        if deadly==1:\n",
    "            self.deadly_events.append(name)\n",
    "        self.init_rate_adj.update({name: np.vstack((np.zeros(self.n) ,np.ones(self.n))).T})\n",
    "        self.init_at_risk[name] = at_risk_ind\n",
    "        \n",
    "    def add_updates(self,name, funcs_dict):\n",
    "        self.updates.update({name:funcs_dict})\n",
    "    \n",
    "    \n",
    "    def run(self, seed=1):\n",
    "        np.random.seed(1)\n",
    "        ## so I can run multiple times... is there a better way?\n",
    "        self.attributes = self.init_attributes.copy() ## attributes just stores sex, age in 1990, dichotomous events \n",
    "        self.rate_adj =self.init_rate_adj.copy()\n",
    "        self.at_risk = self.init_at_risk.copy()\n",
    "        self.ledger = pd.DataFrame(columns=['simulant_id', 'event_name', 'event_time']) ## records events and time they occur\n",
    "        self.clock = np.repeat(0, self.n)\n",
    "      \n",
    "        \n",
    "        ## get baseline events\n",
    "        for events in self.event_names:\n",
    "            self.ledger =self.ledger.append(pd.DataFrame({ 'simulant_id': \\\n",
    "                                 self.attributes[self.attributes[events]==1]['simulant_id'],\n",
    "                                'event_name': events,\n",
    "                                'event_time': 0}))\n",
    "        \n",
    "        #set indicator to index attributes\n",
    "        ind = np.where(self.attributes.Dead==0)\n",
    "        \n",
    "        ## run till I kill everyone. \n",
    "        while np.sum(self.attributes.Dead==0):\n",
    "            temp_log = np.empty([len(ind[0]), len(self.events)])\n",
    "            rand = np.random.uniform(0,1, [len(ind[0]), len(self.events)])\n",
    "            \n",
    "            ## loop thru events ## probably should add in \n",
    "            for i in np.arange(len(self.events)):\n",
    "                name = self.event_names[i]\n",
    "                ## need to find out where time t occurs on the [0,1] range and scale new random numbers\n",
    "                ## this is by far the slowest step and there are other ways this can be done \n",
    "                time_scale = self.events[name]['invfunc'](self, ind, name )*rand[:,i]\n",
    "              \n",
    "                ## get time of event\n",
    "                temp_log[:,i] = self.at_risk[name].iloc[ind]*999+self.events[name]['func'](self, ind, time_scale, name)\n",
    "            \n",
    "            \n",
    "           \n",
    "            ## get details on soonest event\n",
    "            min_ind =temp_log.argmin(axis=1) # get templog index\n",
    "            min_time = temp_log.min(axis=1) # get time it occured\n",
    "            min_name = np.array([self.event_names[i] for i in min_ind]) ## get min event name\n",
    "            \n",
    "\n",
    "            ## update ledger\n",
    "            self.ledger = self.ledger.append(pd.DataFrame({'simulant_id':self.attributes.iloc[ind]['simulant_id'].values,\n",
    "                            'event_name': min_name,\n",
    "                            'event_time':min_time}))\n",
    "            # update run time\n",
    "            self.clock[ind] = min_time.copy()\n",
    "            ## update attributes based on events that occured\n",
    "            for i in np.arange(len(self.updates)):\n",
    "                name = self.updates.keys()[i]\n",
    "                self.updates[name](self, ind, min_ind, min_name)\n",
    "            \n",
    "            ## kill people off\n",
    "            self.attributes['Dead'].iloc[ind] =np.where(np.in1d(min_name, self.deadly_events), 1, 0)\n",
    "            ind =np.where(self.attributes.Dead==0)\n",
    "           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Not the final solution. Not even sure where this belongs\n",
    "def daly_calc(self):\n",
    "       \n",
    "        ## may change this in the future\n",
    "        self.ledger.event_name = np.where(self.ledger.event_name=='IHD Dead', 'Dead', self.ledger.event_name)\n",
    "        \n",
    "        ## calc ylds\n",
    "        dis = self.ledger[self.ledger.event_name=='IHD incidence']\n",
    "        dead = self.ledger[self.ledger.event_name=='Dead']\n",
    "        dis = pd.merge(dis, dead, on='simulant_id', suffixes=('_dis', '_dead'))\n",
    "        ylds = np.sum(dis.event_time_dead -dis.event_time_dis)*.2\n",
    "\n",
    "        #calc ylls\n",
    "        df = pd.merge(self.attributes, dead, on='simulant_id')\n",
    "        df['death_age']= df.Age+df.event_time\n",
    "        df['death_age']= np.round(df['death_age'].values)# because life table doesn't have decimals\n",
    "        df = pd.merge(df, ltable, left_on='Age', right_on= 'age')\n",
    "        return df.ex.sum() +ylds\n",
    "def cost_calc(self):\n",
    "    df = self.ledger.copy()\n",
    "    tx = df[df.event_name=='tx']\n",
    "    dead = df[df.event_name=='Dead']\n",
    "    tx = pd.merge(tx, dead, on='simulant_id', )\n",
    "    return np.sum((tx.event_time_y - tx.event_time_x))*2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Level 2 sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################\n",
    "#add attributes\n",
    "model = sim()\n",
    "model.add_attribute(cohort.columns,cohort)\n",
    "model.add_attribute('IHD Dead', 0) ## in case we want to seperate by death\n",
    "model.add_attribute('tx', 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run w/o intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "#add time-to-event events\n",
    "\n",
    "## when all said and done... not sure this loop is worthwhile. There may be a better way.\n",
    "event_col= ['Mortality_Rate', 'Mortality_Rate', 'Incidence']\n",
    "event_data = [all_death_df, ihd_death_df, ihd_incidence_df]\n",
    "event_names = ['Dead', 'IHD Dead', 'IHD incidence']\n",
    "dead_events = [ 1, 1, 0]\n",
    "ls_at_risk = [model.init_attributes.Dead, np.where(model.init_attributes['IHD incidence']==1, 0,1),  \n",
    "              model.init_attributes['IHD incidence']]\n",
    "\n",
    "for i in np.arange(len(event_col)):\n",
    "      \n",
    "    name = event_names[i]\n",
    "    model.add_events(name, gen_curve(event_data[i], event_col[i]), dead_events[i],ls_at_risk[i])\n",
    "\n",
    "#######################################\n",
    "## add updates\n",
    "\n",
    "# define updates\n",
    "def ihd_update(self, ind, min_ind, min_name):\n",
    "    self.attributes['IHD incidence'].iloc[ind]= np.where(min_name=='IHD incidence'  , 1, self.attributes['IHD incidence'].iloc[ind])\n",
    "    \n",
    "    self.at_risk['IHD Dead'].iloc[ind] = np.where(min_name=='IHD incidence' , 0,self.at_risk['IHD Dead'].iloc[ind] )\n",
    "    self.at_risk['IHD incidence'].iloc[ind] = np.where(min_name=='IHD incidence', 1, self.at_risk['IHD incidence'].iloc[ind])\n",
    "\n",
    "model.add_updates('ihd_update', ihd_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwm6\\AppData\\Local\\Continuum\\Miniconda2\\lib\\site-packages\\ipykernel\\__main__.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\mwm6\\AppData\\Local\\Continuum\\Miniconda2\\lib\\site-packages\\ipykernel\\__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "## run the model.\n",
    "collect_notx = np.empty([100,2])\n",
    "for i in np.arange(100):\n",
    "    model.run(seed=i)\n",
    "    collect_notx[i,:] = np.array([i,daly_calc(model)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run w/ intervention\n",
    "#### add tx updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################\n",
    "# add tx\n",
    "\n",
    "#define tx event\n",
    "def txfunc(self, ind, rand_seq, name):\n",
    "    df = self.attributes.iloc[ind]\n",
    "    ## over 25 by the time 1995 rolls around get tx.\n",
    "    tx_ind = np.where((df.Age>=20) & (df.tx==0) & (5>= self.clock[ind]), 5, 999) \n",
    "    ## for those under 25 by the time 25 rolls around \n",
    "    tx_ind = np.where((df.tx==0) & (df.Age<20) & (25>=df.Age+self.clock[ind]), 25-df.Age, tx_ind)\n",
    "    return tx_ind\n",
    "def txinvfunc(self,ind, name ):\n",
    "    return 1\n",
    "## add tx\n",
    "model.add_events('tx', {'func':txfunc, 'invfunc': txinvfunc},0,0)\n",
    "\n",
    "\n",
    "#######################################\n",
    "## add updates\n",
    "\n",
    "\n",
    "def tx_update(self, ind, min_ind, min_name):\n",
    "    \n",
    "    self.attributes['tx'].ix[ind] = np.where(min_name=='tx' , 1, self.attributes['tx'].ix[ind])\n",
    "    self.at_risk['tx'].ix[ind] = np.where(min_name=='tx', 1, self.at_risk['tx'].ix[ind])\n",
    "    self.rate_adj['IHD incidence'][ind,1] *=np.where(min_name=='tx', 2, 1)\n",
    "    \n",
    "    \n",
    "model.add_updates('tx_update', tx_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mwm6\\AppData\\Local\\Continuum\\Miniconda2\\lib\\site-packages\\ipykernel\\__main__.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\mwm6\\AppData\\Local\\Continuum\\Miniconda2\\lib\\site-packages\\ipykernel\\__main__.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "## run the model.\n",
    "collect_tx = np.empty([100,3])\n",
    "for i in np.arange(100):\n",
    "    model.run(seed=i)\n",
    "    collect_tx[i] = np.array([i,daly_calc(model), cost_calc(model)])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
